{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cassava Disease Dataset Structure + Confusion Matrix V01.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Inceptix/Cassava-leaf-disease-classification/blob/master/Code/Data_Acquisition_and_Understanding/Cassava_Disease_TFRecords_Structure_BaseModel_Confusion_Matrix_V01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWIir9fPox13"
      },
      "source": [
        "**Reference**\n",
        "https://www.kaggle.com/ryanholbrook/tfrecords-basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvtK5mEgo-QR"
      },
      "source": [
        "Setting up the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J5NoX9xomn4",
        "outputId": "de3584d5-58ff-40cb-a265-c00e7518f8b8"
      },
      "source": [
        "import math, re, os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from functools import partial\n",
        "from sklearn.model_selection import train_test_split\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLjyEAJq46-m"
      },
      "source": [
        "Setting up TPUs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVAj95EL5GbW",
        "outputId": "2dd1afa1-ad9e-4235-a454-adf002fe0df2"
      },
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Device:', tpu.master())\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "except:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "print('Number of replicas:', strategy.num_replicas_in_sync)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: grpc://10.86.16.218:8470\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.86.16.218:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.86.16.218:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of replicas: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqpBDtOro1wO"
      },
      "source": [
        "# need to load from a google cloud bucket or you will get\n",
        "# File system scheme '[local]' error\n",
        "# this might change over time so need to go back to getting started notebook: https://www.kaggle.com/thucduong/getting-started-tpus-cassava-leaf-disease/edit\n",
        "# and get the path again\n",
        "GCS_PATH = 'gs://kds-9254a9aba4b37289f07bbbbe4e2af5c952dd2d811a2c823340ca8091'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dnbrEcDpIB7",
        "outputId": "2d052013-6143-4109-d602-d19bce096248"
      },
      "source": [
        "TRAINING_PATH = GCS_PATH + '/train_tfrecords/ld_train*.tfrec' \n",
        "TESTING_PATH = GCS_PATH + '/test_tfrecords/ld_test*.tfrec'\n",
        "TRAINING_FILENAMES, VALID_FILENAMES = train_test_split(\n",
        "    tf.io.gfile.glob(TRAINING_PATH),\n",
        "    test_size=0.35, random_state=5\n",
        ")\n",
        "\n",
        "TEST_FILENAMES = tf.io.gfile.glob(TESTING_PATH)\n",
        "print(TEST_FILENAMES)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['gs://kds-9254a9aba4b37289f07bbbbe4e2af5c952dd2d811a2c823340ca8091/test_tfrecords/ld_test00-1.tfrec']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KJEGZmCrrbx"
      },
      "source": [
        "All the data for this competition is in TF records so we need to decode these TFrecords file in order to get back the (image, label) pair. We can go from TFrecords files to (image, label) pair"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fJENkvbtBMJ"
      },
      "source": [
        "Step 1: Create a function to read TF records and de-serialize these byte strings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y86mUQTpNXE"
      },
      "source": [
        "def read_tfrecord(example, labeled):\n",
        "    tfrecord_format = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
        "    } if labeled else {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
        "    image = decode_image(example['image'])\n",
        "    if labeled:\n",
        "        label = tf.cast(example['target'], tf.int32)\n",
        "        return image, label\n",
        "    idnum = example['image_name']\n",
        "    return image, idnum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRvBJVDytUhd"
      },
      "source": [
        "**example** here means a (image, label) pair. \n",
        "\n",
        "Each example is a byte string that represents an image and a label (called target here) that represents the label [0,1,2,3,4]. But we need a method to convert this string into a data structure in which we can extract the info for the image and its label. \n",
        "\n",
        "This data structure is a dictionary.\n",
        "\n",
        "In some academic literature, for each tfrecord, it's also called a serialized string. \n",
        "\n",
        "We use tf.io.parse_single_example(example, tf_record_format) to **de-serialize** the string back into a dictionary.\n",
        "\n",
        "This dictionary has 2 key-value pairs in which the 2 keys are image and target. The dictionary key-value pairs vary depending on the serialized strings and how the original dataset was encoded. Some dictionaries for some datasets can have 3 or more key value pairs like (image, label, class_name).\n",
        "\n",
        "In short, each example or each tf_record is a serialized string say \"dffgjkshgsj24fjgjks43454\" then we use:\n",
        "tf.io.parse_single_example(\"dffgjkshgsj24fjgjks43454\", tf_record_format) \n",
        "\n",
        "That gives us back the following dict:\n",
        "\n",
        "features {\n",
        "\n",
        "  feature {\n",
        "\n",
        "    key: \"image\",\n",
        "    value: {\n",
        "      bytes_list {\n",
        "        value: \"\\010\\003\\022\\010\\022\\002\\010\\003\\022\\002\\010\\003\\\"$\\000\\000\\000\\000\\001\\000\\000\\000\\002\\000\\000\\000\\003\\000\\000\\000\\004\\000\\000\\000\\005\\000\\000\\000\\006\\000\\000\\000\\007\\000\\000\\000\\010\\000\\000\\000\"\n",
        "      }\n",
        "    }\n",
        "\n",
        "  }\n",
        "\n",
        "  feature {\n",
        "\n",
        "    key: \"target\",\n",
        "    value: {\n",
        "      int64_list {\n",
        "        value: 0\n",
        "      }\n",
        "    }\n",
        "\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "It looks quite confusing but just remember that it's a dict after de-serialization.\n",
        "\n",
        "See more in tf.Example section of the notebook in Reference section above (reference notebook in the first cell) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIAhyOePyJAp"
      },
      "source": [
        "Step 2: Create a function that decode the image's byte lists into an actual image itself.\n",
        "You might have notice that we have a function called decode_image() in our read_tfrecord() function above. We will define this function next!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4772_ars82J"
      },
      "source": [
        "IMAGE_SIZE = [512, 512]\n",
        "\n",
        "# decode the images\n",
        "def decode_image(image):\n",
        "    # decode with 3 channels (RGB)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    # normalize so each image's pixels are from 0 - 255 to 0 - 1 range\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    # apply the normalized pixels value on the images\n",
        "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdzSTUf7y24y"
      },
      "source": [
        "Step 3: Create a function to read TF records from multiple TFrecord files! This allows us to speed up the time to read multiple files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqizb4VOyPUW"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "def load_dataset(filenames, labeled=True, ordered=False):\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n",
        "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
        "    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsBgZj0l1Xws"
      },
      "source": [
        "Summary: All TFrecord files -> load_dataset -> read_tfrecord -> decode_image -> get the actual image and its label\n",
        "\n",
        "(a graphic maybe helpful here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRL5Hkm61m8B"
      },
      "source": [
        "Step 4: Create a function to get the training/testing/validating datasets that we will feed directly into our model. Of course, this notebook is to explore the dataset structure not building a model.\n",
        "\n",
        "This function of course shuffles and batches the (image, label) pairs for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghGIMBVdzHj7"
      },
      "source": [
        "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
        "\n",
        "def get_training_dataset():\n",
        "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)  \n",
        "\n",
        "    # trying out different data augmentation techniques\n",
        "    # dataset = dataset.map(data_augment, num_parallel_calls=AUTOTUNE) \n",
        "    # for technique in data_augment_sequence:\n",
        "    #  dataset = dataset.map(technique, num_parallel_calls=AUTOTUNE) \n",
        "\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.shuffle(2048)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "def get_validation_dataset(ordered=False):\n",
        "    dataset = load_dataset(VALID_FILENAMES, labeled=True, ordered=ordered) \n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.prefetch(AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "def get_test_dataset(ordered=False):\n",
        "    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTOTUNE)\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTmF5Ete6XHz"
      },
      "source": [
        "ALL TRAINING_FILENAMES, VALID_FILENAMES, TEST_FILENAMES are defined above when we were getting the file names from the Google Cloud Bucket."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD6Hwrt360V4"
      },
      "source": [
        "Step 5: Build the model with LR scheduler and RESNET 50 as our base model. We use transfer learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nux_Voc142yz"
      },
      "source": [
        "lr_scheduler = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-5, \n",
        "    decay_steps=10000, \n",
        "    decay_rate=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz8L9gIK65kd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed6f1054-610b-4faf-9757-1b1772607cdf"
      },
      "source": [
        "CLASSES = ['0', '1', '2', '3', '4']\n",
        "with strategy.scope():       \n",
        "    img_adjust_layer = tf.keras.layers.Lambda(tf.keras.applications.resnet50.preprocess_input, input_shape=[*IMAGE_SIZE, 3])\n",
        "    \n",
        "    base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False)\n",
        "    base_model.trainable = False\n",
        "    \n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.BatchNormalization(renorm=True),\n",
        "        img_adjust_layer,\n",
        "        base_model,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(8, activation='relu'),\n",
        "        #tf.keras.layers.BatchNormalization(renorm=True),\n",
        "        tf.keras.layers.Dense(len(CLASSES), activation='softmax')  \n",
        "    ])\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler, epsilon=0.001),\n",
        "        loss='sparse_categorical_crossentropy',  \n",
        "        metrics=['sparse_categorical_accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prBwYKlW7V6v"
      },
      "source": [
        "Step 6: Train the model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLEOzhYD6_VK"
      },
      "source": [
        "# load data\n",
        "train_dataset = get_training_dataset()\n",
        "valid_dataset = get_validation_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geIHVWni7lPk"
      },
      "source": [
        "def count_data_items(filenames):\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1u2IABR7aeY",
        "outputId": "eea98b19-47d9-4a48-ae94-a8be25be7d69"
      },
      "source": [
        "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
        "NUM_VALIDATION_IMAGES = count_data_items(VALID_FILENAMES)\n",
        "\n",
        "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
        "VALID_STEPS = NUM_VALIDATION_IMAGES // BATCH_SIZE\n",
        "EPOCHS = 10\n",
        "\n",
        "history = model.fit(train_dataset, \n",
        "                    steps_per_epoch=STEPS_PER_EPOCH, \n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=valid_dataset,\n",
        "                    validation_steps=VALID_STEPS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "104/104 [==============================] - 91s 640ms/step - loss: 1.5527 - sparse_categorical_accuracy: 0.2221 - val_loss: 1.3196 - val_sparse_categorical_accuracy: 0.5776\n",
            "Epoch 2/10\n",
            "104/104 [==============================] - 55s 529ms/step - loss: 1.3241 - sparse_categorical_accuracy: 0.5891 - val_loss: 1.3100 - val_sparse_categorical_accuracy: 0.6045\n",
            "Epoch 3/10\n",
            "104/104 [==============================] - 55s 530ms/step - loss: 1.2827 - sparse_categorical_accuracy: 0.6157 - val_loss: 1.2622 - val_sparse_categorical_accuracy: 0.6071\n",
            "Epoch 4/10\n",
            "104/104 [==============================] - 55s 527ms/step - loss: 1.2476 - sparse_categorical_accuracy: 0.6111 - val_loss: 1.2252 - val_sparse_categorical_accuracy: 0.6077\n",
            "Epoch 5/10\n",
            "104/104 [==============================] - 55s 530ms/step - loss: 1.2164 - sparse_categorical_accuracy: 0.6102 - val_loss: 1.1956 - val_sparse_categorical_accuracy: 0.6086\n",
            "Epoch 6/10\n",
            "104/104 [==============================] - 55s 532ms/step - loss: 1.1798 - sparse_categorical_accuracy: 0.6162 - val_loss: 1.1718 - val_sparse_categorical_accuracy: 0.6091\n",
            "Epoch 7/10\n",
            "104/104 [==============================] - 56s 537ms/step - loss: 1.1630 - sparse_categorical_accuracy: 0.6109 - val_loss: 1.1526 - val_sparse_categorical_accuracy: 0.6096\n",
            "Epoch 8/10\n",
            "104/104 [==============================] - 55s 532ms/step - loss: 1.1356 - sparse_categorical_accuracy: 0.6156 - val_loss: 1.1365 - val_sparse_categorical_accuracy: 0.6106\n",
            "Epoch 9/10\n",
            "104/104 [==============================] - 55s 531ms/step - loss: 1.1325 - sparse_categorical_accuracy: 0.6148 - val_loss: 1.1230 - val_sparse_categorical_accuracy: 0.6111\n",
            "Epoch 10/10\n",
            "104/104 [==============================] - 55s 530ms/step - loss: 1.1222 - sparse_categorical_accuracy: 0.6107 - val_loss: 1.1121 - val_sparse_categorical_accuracy: 0.6128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iLoq_h574Im"
      },
      "source": [
        "We can experiment with changining the EPOCHS number to see if accuracy improves!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWPDLrwb8Kc-"
      },
      "source": [
        "Step 7: Evaluating the model! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_MzwJGC8X_W"
      },
      "source": [
        "Try using confusion matrix\n",
        "\n",
        "Reference: https://www.geeksforgeeks.org/python-tensorflow-math-confusion_matrix/\n",
        "\n",
        "So we will try producing a labels array and a predictions array for the training data.\n",
        "\n",
        "Since our model's output for each training data is the probabilities of that example belonging to each class, we will pick the class with the highest probability and make that class as our prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDznTaFQ_qAd"
      },
      "source": [
        "# this code will convert our test image data to a float32 \n",
        "def to_float32(image, label):\n",
        "    return tf.cast(image, tf.float32), label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4N3DeQh7rPB",
        "outputId": "1ede05fa-1085-48d7-9f1c-3b794b00323a"
      },
      "source": [
        "valid_ds = get_validation_dataset(ordered=True) \n",
        "print(valid_ds)\n",
        "\n",
        "# https://stackoverflow.com/questions/56226621/how-to-extract-data-labels-back-from-tensorflow-dataset\n",
        "# In case your tf.data.Dataset is batched, the following code will retrieve all the y labels:\n",
        "validation_labels = np.concatenate([y for x, y in valid_ds], axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PrefetchDataset shapes: ((None, 512, 512, 3), (None,)), types: (tf.float32, tf.int32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx_S8mwOG9TK",
        "outputId": "42c7c9b1-c090-4397-c026-05612f00c268"
      },
      "source": [
        "NUM_VALIDATION_IMAGES = count_data_items(VALID_FILENAMES)\n",
        "\n",
        "print('Dataset: {} validation images'.format(NUM_VALIDATION_IMAGES))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset: 8017 validation images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fC3vEV1F8Hy",
        "outputId": "9b9a316f-fa04-4b17-914b-17300591c511"
      },
      "source": [
        "print(len(validation_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1-XK0Ni_dz4",
        "outputId": "bb59b3a3-3c36-471d-ee9d-23b6c920aee3"
      },
      "source": [
        "print('Computing predictions on validation sets ...')\n",
        "valid_images_ds = valid_ds\n",
        "valid_images_ds = valid_images_ds.map(lambda image, idnum: image)\n",
        "probabilities = model.predict(valid_images_ds)\n",
        "predictions = np.argmax(probabilities, axis=-1)\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing predictions on validation sets ...\n",
            "[3 3 3 ... 3 3 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5pVjWSRHOCy",
        "outputId": "185eec18-28c6-4610-e217-1172e2336dbe"
      },
      "source": [
        "print(len(predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxIA0oXuHbgP",
        "outputId": "283d0f44-b3a1-4da1-e96f-cf9686d312e0"
      },
      "source": [
        "# Evaluating confusion matric \n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "res = confusion_matrix(validation_labels,predictions) \n",
        "  \n",
        "# Printing the result \n",
        "print('Confusion_matrix: ', res) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion_matrix:  [[   0   11    4  363   14]\n",
            " [   0   25   21  767   10]\n",
            " [   0    8   18  896    6]\n",
            " [   0    8    6 4851   11]\n",
            " [   0   23   33  923   19]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6NSW25uHmm_",
        "outputId": "f24fadf7-a1fd-4af1-ef4c-709273ddf463"
      },
      "source": [
        "acc = np.sum(res.diagonal()) / np.sum(res)\n",
        "print('Overall accuracy: {} %'.format(acc*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy: 61.282275165273795 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZWOJSspH6is",
        "outputId": "bf926cd7-668d-444a-8151-1b8216a91b40"
      },
      "source": [
        "res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,   11,    4,  363,   14],\n",
              "       [   0,   25,   21,  767,   10],\n",
              "       [   0,    8,   18,  896,    6],\n",
              "       [   0,    8,    6, 4851,   11],\n",
              "       [   0,   23,   33,  923,   19]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpUbuolmIgiA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}