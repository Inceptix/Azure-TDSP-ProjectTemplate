{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cassava_Disease_Classification(Base_for_Eval).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Inceptix/Cassava-leaf-disease-classification/blob/master/Code/Modeling/Cassava_Disease_Classification(Base_Model_Eval).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0whWAaBmdR2q"
      },
      "source": [
        "**Set up environment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pB9NgYtxdM9Z",
        "outputId": "f3ba8bfe-b24d-4ea1-baff-eed6e1ce3e8d"
      },
      "source": [
        "import math, re, os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from functools import partial\n",
        "from sklearn.model_selection import train_test_split\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcRAbUqVdbgD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3873ffa0-c564-421a-ef44-e7f31df1c720"
      },
      "source": [
        "!pip install git+https://github.com/qubvel/classification_models.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/qubvel/classification_models.git\n",
            "  Cloning https://github.com/qubvel/classification_models.git to /tmp/pip-req-build-8m9crc13\n",
            "  Running command git clone -q https://github.com/qubvel/classification_models.git /tmp/pip-req-build-8m9crc13\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Collecting keras_applications<=1.0.8,>=1.0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.15.0)\n",
            "Building wheels for collected packages: image-classifiers\n",
            "  Building wheel for image-classifiers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for image-classifiers: filename=image_classifiers-1.0.0-cp36-none-any.whl size=20030 sha256=9405470d52c360695238064da754f29cffd0582be4bd8514939acf2c7450ca83\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q5phv6o8/wheels/de/2b/fd/29a6d33edb8c28bc7d94e95ea1d39c9a218ac500a3cfb1b197\n",
            "Successfully built image-classifiers\n",
            "Installing collected packages: keras-applications, image-classifiers\n",
            "Successfully installed image-classifiers-1.0.0 keras-applications-1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfZWW59y2idi"
      },
      "source": [
        "from classification_models.tfkeras import Classifiers"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipKoTPRtdklJ"
      },
      "source": [
        "**Detect GPUs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwJ8jwMkdnSX",
        "outputId": "1754b481-df6d-4af1-b404-c2f8cf743aaf"
      },
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Device:', tpu.master())\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "except:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "print('Number of replicas:', strategy.num_replicas_in_sync)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: grpc://10.36.39.26:8470\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.36.39.26:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.36.39.26:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of replicas: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4iR0WXEdnxP"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
        "IMAGE_SIZE = [512, 512]\n",
        "CLASSES = ['0', '1', '2', '3', '4']\n",
        "EPOCHS = 15\n",
        "\n",
        "# need to load from a google cloud bucket or you will get\n",
        "# File system scheme '[local]' error\n",
        "GCS_PATH = 'gs://kds-9254a9aba4b37289f07bbbbe4e2af5c952dd2d811a2c823340ca8091'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTJLVS27fAOd",
        "outputId": "943906f5-39fe-487d-d1f9-6e33b8e108c5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBSTnj_JrXep"
      },
      "source": [
        "# TRAINING_PATH = \"/content/gdrive/My Drive/Project in DS Class/cassava-leaf-disease-classification/train_tfrecords/ld_train*.tfrec\"\n",
        "# TESTING_PATH = \"/content/gdrive/My Drive/Project in DS Class/cassava-leaf-disease-classification/test_tfrecords/ld_test*.tfrec\"\n",
        "TRAINING_PATH = GCS_PATH + '/train_tfrecords/ld_train*.tfrec' \n",
        "TESTING_PATH = GCS_PATH + '/test_tfrecords/ld_test*.tfrec'\n",
        "TRAINING_FILENAMES, VALID_FILENAMES = train_test_split(\n",
        "    tf.io.gfile.glob(TRAINING_PATH),\n",
        "    test_size=0.35, random_state=5\n",
        ")\n",
        "\n",
        "TEST_FILENAMES = tf.io.gfile.glob(TESTING_PATH)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9mt8wt46YsV"
      },
      "source": [
        "# decode the images\n",
        "def decode_image(image):\n",
        "    # decode with 3 channels (RGB)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    # normalize so each image's pixels are from 0 - 255 to 0 - 1 range\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    # apply the normalized pixels value on the images\n",
        "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
        "    return image\n",
        "\n",
        "def read_tfrecord(example, labeled):\n",
        "    tfrecord_format = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
        "    } if labeled else {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n",
        "    }\n",
        "    # decode the images\n",
        "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
        "    image = decode_image(example['image'])\n",
        "    if labeled:\n",
        "        label = tf.cast(example['target'], tf.int32)\n",
        "        return image, label\n",
        "    idnum = example['image_name']\n",
        "    return image, idnum\n",
        "  \n",
        "def load_dataset(filenames, labeled=True, ordered=False):\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n",
        "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
        "    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n",
        "    return dataset"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf0VZCkf7NRQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Egh37V897N4T"
      },
      "source": [
        "**Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrgHxmYf7ROE"
      },
      "source": [
        "# trying out new augmentation techniques\n",
        "\n",
        "# orignal\n",
        "def data_augment_flip_left_right(image, label):\n",
        "    # Thanks to the dataset.prefetch(AUTO) statement in the following function this happens essentially for free on TPU. \n",
        "    # Data pipeline code is executed on the \"CPU\" part of the TPU while the TPU itself is computing gradients.\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    return image, label\n",
        "\n",
        "def data_augment_flip_up_down(image, label):\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    return image, label\n",
        "\n",
        "def data_augment_random_hue(image, label):\n",
        "    # Thanks to the dataset.prefetch(AUTO) statement in the following function this happens essentially for free on TPU. \n",
        "    # Data pipeline code is executed on the \"CPU\" part of the TPU while the TPU itself is computing gradients.\n",
        "    random_delta = random.uniform(0, 0.5)\n",
        "    image = tf.image.random_hue(image, max_delta=random_delta)\n",
        "    return image, label\n",
        "\n",
        "def data_augment_random_jpeg_quality(image, label):\n",
        "    # Thanks to the dataset.prefetch(AUTO) statement in the following function this happens essentially for free on TPU. \n",
        "    # Data pipeline code is executed on the \"CPU\" part of the TPU while the TPU itself is computing gradients.\n",
        "    random_min = random.uniform(0, 100)\n",
        "    random_max = random.uniform(0, 100)\n",
        "    image = tf.image.random_jpeg_quality(image, min_jpeg_quality=random_min, max_jpeg_quality=random_max)\n",
        "    return image, label\n",
        "\n",
        "def data_augment_random_saturation(image, label):\n",
        "    # Thanks to the dataset.prefetch(AUTO) statement in the following function this happens essentially for free on TPU. \n",
        "    # Data pipeline code is executed on the \"CPU\" part of the TPU while the TPU itself is computing gradients.\n",
        "    random_lower = random.uniform(0,100)\n",
        "    random_upper = random.uniform(0,100)\n",
        "    image = tf.image.random_saturation(image, lower=random_lower, upper=random_upper)\n",
        "    return image, label"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0tOdr_s7VQR"
      },
      "source": [
        "data_augment_sequence = (data_augment_flip_left_right, data_augment_flip_up_down)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nSrlJSl7YBk"
      },
      "source": [
        "**Data Loading Methods**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPWgZ7Tz7egW"
      },
      "source": [
        "def get_training_dataset():\n",
        "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)  \n",
        "\n",
        "    # trying out different data augmentation techniques\n",
        "    # dataset = dataset.map(data_augment, num_parallel_calls=AUTOTUNE) \n",
        "    for technique in data_augment_sequence:\n",
        "      dataset = dataset.map(technique, num_parallel_calls=AUTOTUNE) \n",
        "    # original\n",
        "    # dataset = dataset.map(data_augment_flip_left_right, num_parallel_calls=AUTOTUNE)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.shuffle(2048)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "def get_validation_dataset(ordered=False):\n",
        "    dataset = load_dataset(VALID_FILENAMES, labeled=True, ordered=ordered) \n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.prefetch(AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "def get_test_dataset(ordered=False):\n",
        "    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "def count_data_items(filenames):\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HapsoDtx7p6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "126885cc-1623-481e-d4ed-29336aaa4883"
      },
      "source": [
        "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
        "NUM_VALIDATION_IMAGES = count_data_items(VALID_FILENAMES)\n",
        "NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n",
        "\n",
        "print('Dataset: {} training images, {} validation images, {} (unlabeled) test images'.format(\n",
        "    NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset: 13380 training images, 8017 validation images, 1 (unlabeled) test images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYIkg-4h7zzr"
      },
      "source": [
        "**Build the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tzc05a9g73vP"
      },
      "source": [
        "lr_scheduler = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-5, \n",
        "    decay_steps=10000, \n",
        "    decay_rate=0.9)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRw89Pp47_LV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b60379b2-628f-4e08-dade-a324190ffc9b"
      },
      "source": [
        "with strategy.scope():       \n",
        "    img_adjust_layer = tf.keras.layers.Lambda(tf.keras.applications.resnet50.preprocess_input, input_shape=[*IMAGE_SIZE, 3])\n",
        "    \n",
        "    # base\n",
        "    # use base_model.trainable = False\n",
        "    base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False)\n",
        "    base_model.trainable = False\n",
        "    \n",
        "    # customizable model\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.BatchNormalization(renorm=True),\n",
        "        img_adjust_layer,\n",
        "        base_model,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(8, activation='relu'),\n",
        "        #tf.keras.layers.BatchNormalization(renorm=True),\n",
        "        tf.keras.layers.Dense(len(CLASSES), activation='softmax')  \n",
        "    ])\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler, epsilon=0.001),\n",
        "        loss='sparse_categorical_crossentropy',  \n",
        "        metrics=['sparse_categorical_accuracy'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9juDLtkG0GIY"
      },
      "source": [
        "# load our training dataset for EDA\n",
        "training_dataset = get_training_dataset()\n",
        "training_dataset = training_dataset.unbatch().batch(20)\n",
        "train_batch = iter(training_dataset)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8UYeXRS_43B"
      },
      "source": [
        "# load our validation dataset for EDA\n",
        "validation_dataset = get_validation_dataset()\n",
        "validation_dataset = validation_dataset.unbatch().batch(20)\n",
        "valid_batch = iter(validation_dataset)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lTeWrfvAFO4"
      },
      "source": [
        "# load our test dataset for EDA\n",
        "testing_dataset = get_test_dataset()\n",
        "testing_dataset = testing_dataset.unbatch().batch(20)\n",
        "test_batch = iter(testing_dataset)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT8CK3vlAcrQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOGy-rcZAio5"
      },
      "source": [
        "**Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtiMSsKyAmFw"
      },
      "source": [
        "# load data\n",
        "train_dataset = get_training_dataset()\n",
        "valid_dataset = get_validation_dataset()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkRBfI8nApUm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a6d8d2-53fb-46f3-ab5a-290472642ac9"
      },
      "source": [
        "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
        "VALID_STEPS = NUM_VALIDATION_IMAGES // BATCH_SIZE\n",
        "\n",
        "history = model.fit(train_dataset, \n",
        "                    steps_per_epoch=STEPS_PER_EPOCH, \n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=valid_dataset,\n",
        "                    validation_steps=VALID_STEPS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "104/104 [==============================] - 99s 676ms/step - loss: 3.7996 - sparse_categorical_accuracy: 0.1101 - val_loss: 3.1879 - val_sparse_categorical_accuracy: 0.1192\n",
            "Epoch 2/15\n",
            "104/104 [==============================] - 55s 532ms/step - loss: 2.8908 - sparse_categorical_accuracy: 0.1139 - val_loss: 1.9373 - val_sparse_categorical_accuracy: 0.1476\n",
            "Epoch 3/15\n",
            "104/104 [==============================] - 56s 537ms/step - loss: 1.7789 - sparse_categorical_accuracy: 0.2090 - val_loss: 1.4972 - val_sparse_categorical_accuracy: 0.3899\n",
            "Epoch 4/15\n",
            "104/104 [==============================] - 56s 536ms/step - loss: 1.4678 - sparse_categorical_accuracy: 0.4362 - val_loss: 1.3905 - val_sparse_categorical_accuracy: 0.5093\n",
            "Epoch 5/15\n",
            "104/104 [==============================] - 56s 536ms/step - loss: 1.3769 - sparse_categorical_accuracy: 0.5327 - val_loss: 1.3443 - val_sparse_categorical_accuracy: 0.5543\n",
            "Epoch 6/15\n",
            "104/104 [==============================] - 56s 536ms/step - loss: 1.3459 - sparse_categorical_accuracy: 0.5546 - val_loss: 1.3242 - val_sparse_categorical_accuracy: 0.5721\n",
            "Epoch 7/15\n",
            "104/104 [==============================] - 56s 540ms/step - loss: 1.3208 - sparse_categorical_accuracy: 0.5837 - val_loss: 1.3104 - val_sparse_categorical_accuracy: 0.5820\n",
            "Epoch 8/15\n",
            "104/104 [==============================] - 56s 537ms/step - loss: 1.3086 - sparse_categorical_accuracy: 0.5872 - val_loss: 1.3003 - val_sparse_categorical_accuracy: 0.5892\n",
            "Epoch 9/15\n",
            "104/104 [==============================] - 56s 538ms/step - loss: 1.2996 - sparse_categorical_accuracy: 0.5932 - val_loss: 1.2940 - val_sparse_categorical_accuracy: 0.5950\n",
            "Epoch 10/15\n",
            "104/104 [==============================] - 56s 539ms/step - loss: 1.2850 - sparse_categorical_accuracy: 0.6019 - val_loss: 1.2830 - val_sparse_categorical_accuracy: 0.5993\n",
            "Epoch 11/15\n",
            " 43/104 [===========>..................] - ETA: 27s - loss: 1.2846 - sparse_categorical_accuracy: 0.6008"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pkDQv6dG38M"
      },
      "source": [
        "**Use model.Sequential to preprocess images and add that images to the training data**\n",
        "\n",
        "Link: https://www.google.com/url?q=https://www.tensorflow.org/tutorials/images/data_augmentation&sa=D&source=calendar&usd=2&usg=AOvVaw2uVg2QOUsHBQ2tAoiG5H1G"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fFMkMqp-98P"
      },
      "source": [
        "**Evaluation of Base Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IyJCDlz_NVB",
        "outputId": "0dd89cc8-a1a5-485b-895c-3d6cd10d5c78"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "#reload validation set in order\r\n",
        "valid_ordered = get_validation_dataset(ordered=True)\r\n",
        "\r\n",
        "#scrape labels from tuples\r\n",
        "validation_labels = np.concatenate([y for x, y in valid_ordered], axis=0) #image is x, label is y\r\n",
        "\r\n",
        "#print lengths\r\n",
        "# print(len(validation_labels))\r\n",
        "# print(NUM_VALIDATION_IMAGES)\r\n",
        "\r\n",
        "#get predictions\r\n",
        "label_pred = model.predict(valid_ordered)\r\n",
        "\r\n",
        "label_pred = np.argmax(label_pred, axis=1)\r\n",
        "\r\n",
        "#confusion matrix takes grand truth first, and then the predictions\r\n",
        "conf_matrix = confusion_matrix(validation_labels, label_pred)\r\n",
        "print(\"Confusion Matrix\")\r\n",
        "print(conf_matrix)\r\n",
        "\r\n",
        "#accuracy\r\n",
        "acc = np.sum(conf_matrix.diagonal()) / np.sum(conf_matrix)\r\n",
        "print(\"\\nModel Accuracy: {a}\\n\".format(a = acc))\r\n",
        "\r\n",
        "#Distribution matrix\r\n",
        "dist_mat = confusion_matrix(validation_labels, validation_labels)\r\n",
        "print(\"Distribution Matrix\")\r\n",
        "print(dist_mat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "[[   0   13    0  379    0]\n",
            " [   0   64    0  756    3]\n",
            " [   0   15    0  913    0]\n",
            " [   0   23    0 4853    0]\n",
            " [   0   34    0  963    1]]\n",
            "\n",
            "Model Accuracy: 0.6134464263440189\n",
            "\n",
            "Distribution Matrix\n",
            "[[ 392    0    0    0    0]\n",
            " [   0  823    0    0    0]\n",
            " [   0    0  928    0    0]\n",
            " [   0    0    0 4876    0]\n",
            " [   0    0    0    0  998]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPOEvegCS5M2"
      },
      "source": [
        "**Thoughts on the Model**\r\n",
        "\r\n",
        "As visible from the confusion matrix,our modelseems to classify most images as Type 3, the Cassava Mosaic Disease. Infact our accuracy is only as high as it is, because most of the images are of this type.  Oddly enough I thought this would be one of the easier to detect, however it seems that our model is unfairly leaning towards this category."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "VAyahAhlmI-o",
        "outputId": "9595a210-d2f4-4791-c282-dce4fdbf8961"
      },
      "source": [
        "import plotly.express as px\r\n",
        "\r\n",
        "validation_images = np.concatenate([y for x, x in valid_ordered], axis=0) #image is x, label is y\r\n",
        "\r\n",
        "#Display some images\r\n",
        "fig = px.imshow(validation_images[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-c47f09d34a62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Display some images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_ordered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'PrefetchDataset' object does not support indexing"
          ]
        }
      ]
    }
  ]
}